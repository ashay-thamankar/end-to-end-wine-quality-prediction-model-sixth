{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Anaconda Projects\\\\end to end wine quality fifth\\\\end-to-end-wine-quality-fifth'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "os.chdir(Path('F:\\Anaconda Projects\\end to end wine quality sixth\\end-to-end-wine-quality-fifth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\Anaconda Projects\\\\end to end wine quality sixth\\\\end-to-end-wine-quality-fifth'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    model_name: str\n",
    "    # alpha: float\n",
    "    # l1_ration: float\n",
    "    target_column: str\n",
    "    model_to_loop: str\n",
    "    model_params: str\n",
    "    test_array_path: Path\n",
    "    train_array_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-26 11:33:43,463: INFO: utils: NumExpr defaulting to 4 threads.]\n"
     ]
    }
   ],
   "source": [
    "from mlProject.constants import *\n",
    "from mlProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from ensure import ensure_annotations\n",
    "from pathlib import Path\n",
    "def save_object(file_path, obj):\n",
    "    try:\n",
    "        dir_path = os.path.dirname(file_path)\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "        with open(file_path, 'wb') as file_obj:\n",
    "            joblib.dump(obj, file_obj)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "@ensure_annotations\n",
    "def load_object(file_path: Path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file_obj:\n",
    "            return joblib.load(file_obj)\n",
    "    except Exception as e:\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject import *\n",
    "from box import ConfigBox\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def evaluate_models(x_train, x_test, y_train, y_test, models: ConfigBox, params) -> dict:\n",
    "    try:\n",
    "        report = {}\n",
    "        logger.info(f\"Entered to model evaluation list\")\n",
    "\n",
    "        for i in range(len(list(models))):\n",
    "            model = eval(list(models.values())[i])\n",
    "            \n",
    "            param = params[list(models.keys())[i]]\n",
    "\n",
    "            rs = RandomizedSearchCV(model, param)\n",
    "\n",
    "            rs.fit(x_train, y_train)\n",
    "\n",
    "            # model.fit(x_train, y_train)\n",
    "\n",
    "            model.set_params(**rs.best_params_)\n",
    "            model.fit(x_train, y_train)\n",
    "\n",
    "            y_test_pred = model.predict(x_test)\n",
    "\n",
    "            test_model_r2_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "            report[list(models.keys())[i]] = test_model_r2_score\n",
    "\n",
    "        return report\n",
    "\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_filepath = (CONFIG_FILE_PATH),\n",
    "                 params_filepath = (PARAMS_FILE_PATH),\n",
    "                 schema_filepath = (SCHEME_FILE_PATH),\n",
    "                 model_p_filepath = (MODEL_P_FILE_PATH)):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "        self.model_p = read_yaml(model_p_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "        print(self.config)\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "\n",
    "        config = self.config.model_trainer\n",
    "        # params = self.params.ElasticNet\n",
    "        schema = self.schema.TARGET_COLUMN\n",
    "        model = self.params.models\n",
    "        model_p = self.model_p.params\n",
    "        # print(config)\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path=config.train_data_path,\n",
    "            test_data_path=config.test_data_path,\n",
    "            model_name=config.model_name,\n",
    "            # alpha=params.alpha,\n",
    "            # l1_ration=params.l1_ratio,\n",
    "            target_column=schema.name,\n",
    "            model_to_loop = model,\n",
    "            model_params = model_p,\n",
    "            train_array_path=config.train_array_path,\n",
    "            test_array_path=config.test_array_path\n",
    "        )\n",
    "\n",
    "        return model_trainer_config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import joblib\n",
    "# from mlProject.utils.common import evaluate_models\n",
    "from mlProject import *\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config  = config\n",
    "\n",
    "    def train(self):\n",
    "        # train_data = pd.read_csv(self.config.train_data_path)\n",
    "        # test_data = pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "        # train_x = train_data.drop([self.config.target_column], axis=1)\n",
    "        # train_y = train_data[self.config.target_column]\n",
    "\n",
    "        # test_x = test_data.drop([self.config.target_column], axis=1)\n",
    "        # test_y = test_data[self.config.target_column]\n",
    "        # print(self.config)\n",
    "        logger.info('Training of array started')\n",
    "        train_data = load_object(Path(self.config.train_array_path))\n",
    "        test_data  = load_object(Path(self.config.test_array_path))\n",
    "\n",
    "        train_x, train_y, test_x , test_y = (\n",
    "            train_data[:,:-1],\n",
    "            train_data[:,-1],\n",
    "            test_data[:,:-1],\n",
    "            test_data[:,-1]\n",
    "        )\n",
    "        models = self.config.model_to_loop\n",
    "        model_p = self.config.model_params\n",
    "        logger.info(f\"Models parameters are ready to print\")\n",
    "        print(model_p)\n",
    "        print(model_p.keys())\n",
    "        print(model_p.values())\n",
    "\n",
    "        model_report:dict = evaluate_models(x_train=train_x, y_train=train_y, x_test=test_x, y_test=test_y, models=models, params=model_p)\n",
    "\n",
    "        \n",
    "        best_model_score = max(sorted(model_report.values()))\n",
    "\n",
    "        best_model_name = list(model_report.keys())[\n",
    "            list(model_report.values()).index(best_model_score)\n",
    "            ]\n",
    "\n",
    "        best_model = models[best_model_name]\n",
    "\n",
    "        logging.info(f\"Best model is {best_model_name} and its r2 score is {best_model_score}\")\n",
    "\n",
    "        joblib.dump(best_model, os.path.join(self.config.root_dir, self.config.model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-26 11:34:10,097: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-01-26 11:34:10,104: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-01-26 11:34:10,111: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-01-26 11:34:10,159: INFO: common: yaml file: model_params.yaml loaded successfully]\n",
      "[2024-01-26 11:34:10,163: INFO: common: Created directory at artifacts]\n",
      "{'artifacts_root': 'artifacts', 'data_ingestion': {'root_dir': 'artifacts/data_ingestion', 'source_URL': 'https://github.com/ashay-thamankar/raw-data-to-practice/raw/main/winequality-red.zip', 'local_data_file': 'artifacts/data_ingestion/data.zip', 'unzip_dir': 'artifacts/data_ingestion'}, 'data_validation': {'root_dir': 'artifacts/data_validation', 'unzip_data_dir': 'artifacts/data_ingestion/winequality-red.csv', 'STATUS_FILE': 'artifacts/data_validation/staus.txt'}, 'data_transformation': {'root_dir': 'artifacts/data_transformation', 'data_path': 'artifacts/data_ingestion/winequality-red.csv', 'preprocessor_path': 'artifacts/data_transformation/preprocessor.joblib', 'test_array_path': 'artifacts/data_transformation/test_array.joblib', 'train_array_path': 'artifacts/data_transformation/train_array.joblib'}, 'model_trainer': {'root_dir': 'artifacts/model_trainer', 'train_data_path': 'artifacts/data_transformation/train.csv', 'test_data_path': 'artifacts/data_transformation/test.csv', 'model_name': 'model.joblib', 'test_array_path': 'artifacts/data_transformation/test_array.joblib', 'train_array_path': 'artifacts/data_transformation/train_array.joblib'}, 'model_evaluation': {'root_dir': 'artifacts/model_evaluation', 'test_data_path': 'artifacts/data_transformation/test.csv', 'model_path': 'artifacts/model_trainer/model.joblib', 'metric_file_name': 'artifacts/model_evaluation/metrics.json'}}\n",
      "{'root_dir': 'artifacts/model_trainer', 'train_data_path': 'artifacts/data_transformation/train.csv', 'test_data_path': 'artifacts/data_transformation/test.csv', 'model_name': 'model.joblib', 'test_array_path': 'artifacts/data_transformation/test_array.joblib', 'train_array_path': 'artifacts/data_transformation/train_array.joblib'}\n",
      "[2024-01-26 11:34:10,167: INFO: common: Created directory at artifacts/model_trainer]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelTrainerConfig(root_dir='artifacts/model_trainer', train_data_path='artifacts/data_transformation/train.csv', test_data_path='artifacts/data_transformation/test.csv', model_name='model.joblib', target_column='quality', model_to_loop=ConfigBox({'Linear Regression': 'LinearRegression()', 'K-Neighbors Regressor': 'KNeighborsRegressor()', 'Decision Tree': 'DecisionTreeRegressor()', 'Random Forest Regressor': 'RandomForestRegressor()', 'XGBRegressor': 'XGBRegressor()', 'CatBoosting Regressor': 'CatBoostRegressor(verbose=False)', 'AdaBoost Regressor': 'AdaBoostRegressor()', 'Gradient Boosting': 'GradientBoostingRegressor()', 'ElasticNet': 'ElasticNet()'}), model_params=ConfigBox({'Linear Regression': {'fit_intercept': [True, False], 'copy_X': [True, False], 'n_jobs': [-1, 1, 'None']}, 'K-Neighbors Regressor': {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [10, 20, 30], 'p': [1, 2], 'metric': ['minkowski', 'euclidean', 'manhattan']}, 'Decision Tree': {'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson']}, 'Random Forest Regressor': {'n_estimators': [8, 16, 32, 64, 128, 256]}, 'XGBRegressor': {'learning_rate': [0.1, 0.01, 0.05, 0.001], 'n_estimators': [8, 16, 32, 64, 128, 256]}, 'CatBoosting Regressor': {'depth': [6, 8, 10], 'learning_rate': [0.01, 0.05, 0.1], 'iterations': [30, 50, 100]}, 'AdaBoost Regressor': {'learning_rate': [0.1, 0.01, 0.5, 0.001], 'n_estimators': [8, 16, 32, 64, 128, 256]}, 'Gradient Boosting': {'learning_rate': [0.1, 0.01, 0.05, 0.001], 'subsample': [0.6, 0.7, 0.75, 0.8, 0.85, 0.9], 'n_estimators': [8, 16, 32, 64, 128, 256]}, 'ElasticNet': {'alpha': [0.2, 0.5, 0.7, 0.9], 'l1_ratio': [0.2, 0.5, 0.7, 0.9]}}), test_array_path='artifacts/data_transformation/test_array.joblib', train_array_path='artifacts/data_transformation/train_array.joblib')\n",
      "[2024-01-26 11:34:10,169: INFO: 3462842478: Training of array started]\n",
      "[2024-01-26 11:34:10,174: INFO: 3462842478: Models parameters are ready to print]\n",
      "{'Linear Regression': {'fit_intercept': [True, False], 'copy_X': [True, False], 'n_jobs': [-1, 1, 'None']}, 'K-Neighbors Regressor': {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [10, 20, 30], 'p': [1, 2], 'metric': ['minkowski', 'euclidean', 'manhattan']}, 'Decision Tree': {'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson']}, 'Random Forest Regressor': {'n_estimators': [8, 16, 32, 64, 128, 256]}, 'XGBRegressor': {'learning_rate': [0.1, 0.01, 0.05, 0.001], 'n_estimators': [8, 16, 32, 64, 128, 256]}, 'CatBoosting Regressor': {'depth': [6, 8, 10], 'learning_rate': [0.01, 0.05, 0.1], 'iterations': [30, 50, 100]}, 'AdaBoost Regressor': {'learning_rate': [0.1, 0.01, 0.5, 0.001], 'n_estimators': [8, 16, 32, 64, 128, 256]}, 'Gradient Boosting': {'learning_rate': [0.1, 0.01, 0.05, 0.001], 'subsample': [0.6, 0.7, 0.75, 0.8, 0.85, 0.9], 'n_estimators': [8, 16, 32, 64, 128, 256]}, 'ElasticNet': {'alpha': [0.2, 0.5, 0.7, 0.9], 'l1_ratio': [0.2, 0.5, 0.7, 0.9]}}\n",
      "dict_keys(['Linear Regression', 'K-Neighbors Regressor', 'Decision Tree', 'Random Forest Regressor', 'XGBRegressor', 'CatBoosting Regressor', 'AdaBoost Regressor', 'Gradient Boosting', 'ElasticNet'])\n",
      "dict_values([ConfigBox({'fit_intercept': [True, False], 'copy_X': [True, False], 'n_jobs': [-1, 1, 'None']}), ConfigBox({'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [10, 20, 30], 'p': [1, 2], 'metric': ['minkowski', 'euclidean', 'manhattan']}), ConfigBox({'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson']}), ConfigBox({'n_estimators': [8, 16, 32, 64, 128, 256]}), ConfigBox({'learning_rate': [0.1, 0.01, 0.05, 0.001], 'n_estimators': [8, 16, 32, 64, 128, 256]}), ConfigBox({'depth': [6, 8, 10], 'learning_rate': [0.01, 0.05, 0.1], 'iterations': [30, 50, 100]}), ConfigBox({'learning_rate': [0.1, 0.01, 0.5, 0.001], 'n_estimators': [8, 16, 32, 64, 128, 256]}), ConfigBox({'learning_rate': [0.1, 0.01, 0.05, 0.001], 'subsample': [0.6, 0.7, 0.75, 0.8, 0.85, 0.9], 'n_estimators': [8, 16, 32, 64, 128, 256]}), ConfigBox({'alpha': [0.2, 0.5, 0.7, 0.9], 'l1_ratio': [0.2, 0.5, 0.7, 0.9]})])\n",
      "[2024-01-26 11:34:10,179: INFO: 3325975768: Entered to model evaluation list]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "15 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'n_jobs' parameter of LinearRegression must be None or an instance of 'int'. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.32173891 0.32173891 0.32173891 0.32249015 0.32249015        nan\n",
      " 0.32249015        nan 0.32173891        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Linear Regression': 0.4019459730722381, 'K-Neighbors Regressor': 0.5425946067391587, 'Decision Tree': -0.023326708408673014, 'Random Forest Regressor': 0.5237928006946831, 'XGBRegressor': 0.47887715253929086, 'CatBoosting Regressor': 0.4957674546314439, 'AdaBoost Regressor': 0.4173218939857646, 'Gradient Boosting': 0.43862518523491656, 'ElasticNet': 0.36196096133633715}\n",
      "[2024-01-26 11:37:08,413: INFO: 3462842478: Best model is K-Neighbors Regressor and its r2 score is 0.5425946067391587]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
